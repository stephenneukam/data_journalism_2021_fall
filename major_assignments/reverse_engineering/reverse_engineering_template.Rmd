---
title: "Reverse Engineering Project"
author: "Student names here"
date: "Date here"
output:
  html_document:
    theme: cerulean
    highlight: pygments
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction 

In this notebook, we are reverse engineering the story, "As police struggle to solve homicides, Baltimore residents see an ‘open season for killing’" (https://www.washingtonpost.com/investigations/as-police-struggle-to-solve-homicides-baltimore-residents-see-an-open-season-for-killing/2018/12/26/7ee561e4-fb24-11e8-8c9a-860ce2a8148f_story.html)

## Load libraries

Loading required libraries for this analysis.

```{r echo=FALSE, message=FALSE}
options(scipen=999)
library(tidyverse)
library(lubridate)
library(refinr)
```

## Load and Cleaning Data

In this section, describe the source of the data, write a basic data dictionary for data you are working with, and discuss any caveats or issues you discovered working with this data. 

```{r}
# Load required data

# Path to data should be loaded from folder "data" i.e. read_csv("data/name_of_data.csv")

# Clean required data and prepare for analysis if needed. 

homicide_data <- read_csv("data/homicide-data.csv")

# This data was collected by Washington Post journalists totaling homicide info form 50 American cities. It was collected in different formats and different jurisdictions and was cross-referenced with FBI data to ensure accuracy. The data has already been standardized and cleaned by Washington Post reporters so the datasets were easy to manuveur. I double-checked the accuracy and consistency of spelling in OpenRefine.

```

## Sentences to Engineer
In this notebook, we are reverse engineering five sentences from the story.

### Sentence 1

* **Sentence text**: “As Baltimore has seen a stunning surge of violence, with nearly a killing each day for the past three years in a city of 600,000, homicide arrests have plummeted. City police made an arrest in 41 percent of homicides in 2014; last year, the rate was just 27 percent, a 14 percentage point drop.”
* **Analysis summary**: I was able to confirm the findings of this paragraph and data analysis by The Post. By separating the data from Baltimore into different years, it was then possible to summarise how many cases had been closed by arrest and divide that by the total number of homicides to find the arrest percentage.

```{r}
# Put code to reverse engineer sentence here
baltimore_homicides <- homicide_data %>%
  filter(city == "Baltimore")
# Here we use filter and str_detect to create 11 different datasets for each year of homicide data that we are provided.
o_seven_homicides <- baltimore_homicides %>%
  filter(str_detect(reported_date, "^2007"))
o_eight_homicides <- baltimore_homicides %>%
  filter(str_detect(reported_date, "^2008"))
o_nine_homicides <- baltimore_homicides %>%
  filter(str_detect(reported_date, "^2009"))
ten_homicides <- baltimore_homicides %>%
  filter(str_detect(reported_date, "^2010"))
eleven_homicides <- baltimore_homicides %>%
  filter(str_detect(reported_date, "^2011"))
twelve_homicides <- baltimore_homicides %>%
  filter(str_detect(reported_date, "^2012"))
thirteen_homicides <- baltimore_homicides %>%
  filter(str_detect(reported_date, "^2013"))
fourteen_homicides <- baltimore_homicides %>%
  filter(str_detect(reported_date, "^2014"))
fifteen_homicides <- baltimore_homicides %>%
  filter(str_detect(reported_date, "^2015"))
sixteen_homicides <- baltimore_homicides %>%
  filter(str_detect(reported_date, "^2016"))
seventeen_homicides <- baltimore_homicides %>%
  filter(str_detect(reported_date, "^2017"))
# Here we use group_by to isolate the disposition field and summarise the amount of cases that were "closed by arrest." We find that there were 86 cases where there were arrests in 2014 out of 211 total cases. That is an arrest percentage of 41 percent. 
fourteen_homicides %>%
  group_by(disposition) %>%
  summarise(arrested_amount = sum(disposition == "Closed by arrest")) %>%
  arrange(desc(arrested_amount))
86/211
# Here we run the same code for the 2017 set of data and find that 93 arrests were made from a total of 340 cases — a total of 27 percent.
seventeen_homicides %>%
  group_by(disposition) %>%
  summarise(arrested_amount = sum(disposition == "Closed by arrest")) %>%
  arrange(desc(arrested_amount))
93/340
# Display results of code below this codeblock

```

### Sentence 2

* **Sentence text**: "While homicide rates remain near historical lows in most American cities, Baltimore and Chicago are now both seeing murder tallies that rival the early 2000s."
* **Analysis summary**: I was able to confirm the finding that recent homicide numbers rivaled those of the early 2000s based on the total number of homicides seen each year. When comparing the results we can see a steady increase in homicides throughout each year. When looking at 2007 and 2017, there are significantly more homicides in the latter year, as 2007 saw 280 homicides and 2017 saw 340. 

```{r}
# Put code to reverse engineer sentence here
baltimore_homicides <- homicide_data %>%
  filter(city == "Baltimore")
#Here, we'll use filter and str_detect to create the same datasets from above for each year reported.
o_seven_homicides <- baltimore_homicides %>%
  filter(str_detect(reported_date, "^2007"))
o_eight_homicides <- baltimore_homicides %>%
  filter(str_detect(reported_date, "^2008"))
o_nine_homicides <- baltimore_homicides %>%
  filter(str_detect(reported_date, "^2009"))
ten_homicides <- baltimore_homicides %>%
  filter(str_detect(reported_date, "^2010"))
eleven_homicides <- baltimore_homicides %>%
  filter(str_detect(reported_date, "^2011"))
twelve_homicides <- baltimore_homicides %>%
  filter(str_detect(reported_date, "^2012"))
thirteen_homicides <- baltimore_homicides %>%
  filter(str_detect(reported_date, "^2013"))
fourteen_homicides <- baltimore_homicides %>%
  filter(str_detect(reported_date, "^2014"))
fifteen_homicides <- baltimore_homicides %>%
  filter(str_detect(reported_date, "^2015"))
sixteen_homicides <- baltimore_homicides %>%
  filter(str_detect(reported_date, "^2016"))
seventeen_homicides <- baltimore_homicides %>%
  filter(str_detect(reported_date, "^2017"))
#Now we can summarize each data set and see how many homicide cases there were for each year. If done right, we should see an increase. 
o_seven_homicides%>%
  summarise(o_seven_total=n())
o_eight_homicides%>%
  summarise(o_eight_total=n())
o_nine_homicides%>%
  summarise(o_nine_total=n())
ten_homicides%>%
  summarise(ten_total=n())
eleven_homicides%>%
  summarise(eleven_total=n())
twelve_homicides%>%
  summarise(twelve_total=n())
thirteen_homicides%>%
  summarise(thirteen_total=n())
fourteen_homicides%>%
  summarise(fourteen_total=n())
fifteen_homicides%>%
  summarise(fifteen_total=n())
sixteen_homicides%>%
  summarise(sixteen_total=n())
seventeen_homicides%>%
  summarise(seventeen_total=n())
# Display results of code below this codeblock

```

### Sentence 3

* **Sentence text**: “For most of the decade before 2015, Baltimore’s annual homicide arrest rate hovered at about 40 percent. Since 2015, the arrest rate hasn’t topped 30 percent in any year. 
* **Analysis summary**: The only reason I was not able to confirm the finding was because I was unsure of how to move forward in finding the averages of the data. I think however after you check this Derek and make sure I'm on the right track, then we will be able to see that Baltimore's homicide rate decreased at ten percent, and has remained that way since. 

```{r}
# Put code to reverse engineer sentence here
library(tidyverse)

read_csv("~/Documents/GitHub/data-homicides/homicide-data.csv")

homicide_data <-read_csv("homicide-data.csv")

baltimore_homicides <- homicide_data %>%
  filter(city == "Baltimore") %>%
  group_by(reported_date = "2007-2014") %>%
  
I am stuck here now. So I know I need the data from 2007-2014 complied together to get the averages and then the data from 2014 on to get those averages. Would I create a new dataframe from here? Because then I know I could so something like this- 

  nrow(first_half_data)?second_half_data *100 - to find the averages 
# Display results of code below this codeblock

```

### Sentence 4

* **Sentence text**: 
* **Analysis summary**: [Write up two to three sentences describing the results of your analysis.  Were you able to confirm the finding? If not, why not?]

```{r}
# Put code to reverse engineer sentence here

# Display results of code below this codeblock

```

### Sentence 5

* **Sentence text**: [Paste in sentence to engineer here]
* **Analysis summary**: [Write up two to three sentences describing the results of your analysis.  Were you able to confirm the finding? If not, why not?]

```{r}
# Put code to reverse engineer sentence here

# Display results of code below this codeblock

```

-30-
